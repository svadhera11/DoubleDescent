# -*- coding: utf-8 -*-
"""mnist_code1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14j1bW7vstZ6Ou3X3SL2Nm4Z81zzroDVE
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import TensorDataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
import os
from tqdm import tqdm

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SUBSET_SIZE = 4000
INPUT_DIM = 784     # d = 28*28
NUM_CLASSES = 10    # K = 10
EPOCHS = 6000
LR_INIT = 0.1       # Learning rate
MOMENTUM = 0.95     # SGD Momentum
BATCH_SIZE = 256

NOISE_LEVELS = [0.0, 0.1, 0.2]

hidden_units_list = [
    10, 30, 40,             # Under-parameterized
    46, 50, 54, 60,         # Around threshold (~50)
    100, 500, 1000          # Over-parameterized
]

class SimpleNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

    def count_parameters(self):
        return sum(p.numel() for p in self.parameters())

def get_data(noise_ratio=0.0):
    print("Loading data... (Ensure Internet is ENABLED in Kaggle settings)")
    try:
        raw_train = torchvision.datasets.MNIST(root='./data', train=True, download=True)
        raw_test = torchvision.datasets.MNIST(root='./data', train=False, download=True)
    except RuntimeError as e:
        print("\nERROR: Failed to download MNIST. Enable 'Internet' in Kaggle Settings.\n")
        raise e

    # Extract Subset
    all_indices = torch.randperm(len(raw_train))[:SUBSET_SIZE]
    train_images = raw_train.data[all_indices].float() / 255.0
    train_labels = raw_train.targets[all_indices].clone()

    # Apply Label Noise
    if noise_ratio > 0:
        n_noisy = int(SUBSET_SIZE * noise_ratio)
        noisy_indices = torch.randperm(SUBSET_SIZE)[:n_noisy]
        random_labels = torch.randint(0, NUM_CLASSES, (n_noisy,))
        train_labels[noisy_indices] = random_labels

    # Normalize
    mean = 0.1307
    std = 0.3081
    train_images = (train_images - mean) / std

    test_images = raw_test.data.float() / 255.0
    test_labels = raw_test.targets
    test_images = (test_images - mean) / std

    train_dataset = TensorDataset(train_images.unsqueeze(1), train_labels)
    test_dataset = TensorDataset(test_images.unsqueeze(1), test_labels)

    kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **kwargs)
    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, **kwargs)

    return train_loader, test_loader

def train_model(model, train_loader, epochs, criterion, device):
    optimizer = optim.SGD(model.parameters(), lr=LR_INIT, momentum=MOMENTUM)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=epochs//2, gamma=0.1)

    model.train()

    for epoch in range(epochs):
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=NUM_CLASSES).float()

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels_one_hot)

            loss.backward()
            optimizer.step()
        scheduler.step()

        # Early Stopping
        if epoch % 100 == 0 and loss.item() < 1e-5:
            # print(f"Early stopping at epoch {epoch}")
            break

    return model

def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=NUM_CLASSES).float()
            outputs = model(inputs)

            loss = criterion(outputs, labels_one_hot)
            total_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return total_loss / total, 1.0 - (correct / total)

def run_experiment():
    print(f"Running on {DEVICE}")
    gpu_count = torch.cuda.device_count()
    print(f"GPU Count: {gpu_count}")

    criterion = nn.MSELoss()

    save_dir = 'saved_models'
    os.makedirs(save_dir, exist_ok=True)

    all_results = {}
    threshold_params = SUBSET_SIZE * NUM_CLASSES

    noise_iterator = tqdm(NOISE_LEVELS, desc="Noise Levels")

    for noise in noise_iterator:
        noise_iterator.set_description(f"Noise Level {int(noise*100)}%")
        train_loader, test_loader = get_data(noise_ratio=noise)

        results = {'params': [], 'train_err': [], 'test_err': [], 'train_mse': [], 'test_mse': []}

        model_iterator = tqdm(hidden_units_list, desc="Training Models", leave=False)

        for H in model_iterator:
            model = SimpleNN(INPUT_DIM, H, NUM_CLASSES).to(DEVICE)

            num_params = model.count_parameters()

            if gpu_count > 1:
                model = nn.DataParallel(model)

            model = train_model(model, train_loader, EPOCHS, criterion, DEVICE)

            model_filename = f"model_noise_{noise:.1f}_hidden_{H}.pth"
            save_path = os.path.join(save_dir, model_filename)

            if isinstance(model, nn.DataParallel):
                torch.save(model.module.state_dict(), save_path)
            else:
                torch.save(model.state_dict(), save_path)

            train_mse, train_err = evaluate(model, train_loader, criterion, DEVICE)
            test_mse, test_err = evaluate(model, test_loader, criterion, DEVICE)

            results['params'].append(num_params)
            results['train_err'].append(train_err)
            results['test_err'].append(test_err)
            results['train_mse'].append(train_mse)
            results['test_mse'].append(test_mse)

        all_results[noise] = results

    return all_results, threshold_params

def plot_results(all_results, threshold):
    plt.figure(figsize=(10, 6))
    colors = ['blue', 'green', 'red']

    for i, noise in enumerate(NOISE_LEVELS):
        res = all_results[noise]
        label = f'Noise {int(noise*100)}%'
        plt.plot(res['params'], res['test_err'], 'o-', color=colors[i], label=label, markersize=4)

    plt.axvline(x=threshold, color='black', linestyle='--', label='Interpolation Threshold')
    plt.xscale('log')
    plt.xlabel('Number of Parameters')
    plt.ylabel('Test Zero-One Loss (Error Rate)')
    plt.title(f'Double Descent under Label Noise (n={SUBSET_SIZE})')
    plt.legend()
    plt.grid(True, which="both", ls="-", alpha=0.5)
    plt.tight_layout()
    plt.savefig('mnist_noise_comparison.png')
    print("Plot saved to mnist_noise_comparison.png")
    plt.show()

if __name__ == "__main__":
    data, threshold = run_experiment()
    plot_results(data, threshold)