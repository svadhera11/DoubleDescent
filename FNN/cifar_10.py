# -*- coding: utf-8 -*-
"""cifar-10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rPu-_B5mAj2psIMKmAceiOHroRzBRbqX
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import TensorDataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
import os
import csv
from tqdm import tqdm

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
TRAIN_MODE = True
SUBSET_SIZE = 960   # n = 960
INPUT_DIM = 64      # d = 8*8 grayscale
NUM_CLASSES = 2     # K = 2
BATCH_SIZE = 128
EPOCHS = 6000
LR_INIT = 0.01      # Reduced LR slightly for stability with small N
MOMENTUM = 0.95

# Experiment Parameters
NOISE_LEVELS = [0.0, 0.1, 0.2]

# List of Hidden Units (H)
# Threshold (n=960, K=2) => Params = 1920
# Params = (64+1)H + (H+1)2 = 67H + 2
# Threshold H = 1918 / 67 â‰ˆ 28.6
hidden_units_list = [
    2, 4, 8, 15, 20, 24,        # Under-parameterized
    26, 28, 29, 30, 32, 36,     # Around threshold (~29)
    50, 100, 200, 500, 1000     # Over-parameterized
]

class SimpleNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

    def count_parameters(self):
        return sum(p.numel() for p in self.parameters())

def get_data(noise_ratio=0.0):
    print(f"Loading CIFAR-10 (Cat vs Dog, 8x8 Grayscale) for Noise {noise_ratio}...")

    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),
        transforms.Resize((8, 8)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,)) # Standardize roughly
    ])

    try:
        raw_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
        raw_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    except RuntimeError as e:
        print("\nERROR: Failed to download CIFAR-10. Enable 'Internet' in Kaggle Settings.\n")
        raise e

    def filter_classes(dataset, classes=[3, 5]):
        # classes: 3=cat, 5=dog
        targets = torch.tensor(dataset.targets)
        indices = torch.nonzero(torch.tensor([t in classes for t in targets])).flatten()

        # Subsample data
        data = torch.stack([dataset[i][0] for i in indices])
        labels = targets[indices]

        new_labels = torch.zeros_like(labels)
        new_labels[labels == classes[1]] = 1

        return data, new_labels

    print("Filtering classes...")
    X_train_full, y_train_full = filter_classes(raw_train)
    X_test_full, y_test_full = filter_classes(raw_test)

    g = torch.Generator()
    g.manual_seed(42)
    subset_indices = torch.randperm(len(X_train_full), generator=g)[:SUBSET_SIZE]

    train_images = X_train_full[subset_indices]
    train_labels = y_train_full[subset_indices].clone()

    test_images = X_test_full
    test_labels = y_test_full

    if noise_ratio > 0:
        n_noisy = int(SUBSET_SIZE * noise_ratio)
        torch.manual_seed(42)
        noisy_indices = torch.randperm(SUBSET_SIZE)[:n_noisy]
        # Random binary labels (0 or 1)
        random_labels = torch.randint(0, NUM_CLASSES, (n_noisy,))
        train_labels[noisy_indices] = random_labels

    # Create Datasets
    train_dataset = TensorDataset(train_images, train_labels)
    test_dataset = TensorDataset(test_images, test_labels)

    kwargs = {'num_workers': 2, 'pin_memory': True} if torch.cuda.is_available() else {}

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True if TRAIN_MODE else False, **kwargs)
    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, **kwargs)

    return train_loader, test_loader

def train_model(model, train_loader, epochs, criterion, device):
    optimizer = optim.SGD(model.parameters(), lr=LR_INIT, momentum=MOMENTUM)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=epochs//2, gamma=0.1)

    model.train()

    for epoch in range(epochs):
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=NUM_CLASSES).float()

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels_one_hot)
            loss.backward()
            optimizer.step()
        scheduler.step()


    return model

def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0
    total = 0
    correct = 0
    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=NUM_CLASSES).float()
            outputs = model(inputs)

            loss = criterion(outputs, labels_one_hot)
            total_loss += loss.item() * inputs.size(0)

            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    mse = total_loss / total
    error_rate = 1.0 - (correct / total)
    return mse, error_rate

def run_experiment():
    print(f"--- EXPERIMENT MODE: {'TRAINING' if TRAIN_MODE else 'EVALUATION'} ---")
    print(f"Device: {DEVICE}")
    print(f"Dataset: CIFAR-10 (2-Class, 8x8 Grayscale)")

    save_dir = 'saved_models_cifar'
    os.makedirs(save_dir, exist_ok=True)

    input_save_dir = '/kaggle/input/notebook0b400d112d/saved_models_cifar'

    log_filename = 'cifar_experiment_logs.csv'
    if TRAIN_MODE:
        with open(log_filename, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['noise_level', 'hidden_units', 'params', 'train_mse', 'test_mse', 'train_err', 'test_err'])

    criterion = nn.MSELoss()
    all_results = {}
    threshold_params = SUBSET_SIZE * NUM_CLASSES # 960 * 2 = 1920

    for noise in NOISE_LEVELS:
        train_loader, test_loader = get_data(noise_ratio=noise)

        results = {'params': [], 'train_mse': [], 'test_mse': []}

        print(f"\nProcessing Noise Level {int(noise*100)}%...")

        for H in tqdm(hidden_units_list):
            model = SimpleNN(INPUT_DIM, H, NUM_CLASSES).to(DEVICE)
            num_params = model.count_parameters()
            model_filename = f"cifar_model_noise_{noise:.1f}_hidden_{H}.pth"

            if TRAIN_MODE:
                model = train_model(model, train_loader, EPOCHS, criterion, DEVICE)
                save_path = os.path.join(save_dir, model_filename)
                torch.save(model.state_dict(), save_path)
            else:
                save_path = os.path.join(save_dir, model_filename)
                if not os.path.exists(save_path):
                    save_path = os.path.join(input_save_dir, model_filename)

                if not os.path.exists(save_path):
                    continue

                try:
                    state_dict = torch.load(save_path, map_location=DEVICE)
                    model.load_state_dict(state_dict)
                except Exception as e:
                    print(f"Error loading {model_filename}: {e}")
                    continue

            train_mse, train_err = evaluate(model, train_loader, criterion, DEVICE)
            test_mse, test_err = evaluate(model, test_loader, criterion, DEVICE)

            results['params'].append(num_params)
            results['train_mse'].append(train_mse)
            results['test_mse'].append(test_mse)

            if TRAIN_MODE:
                with open(log_filename, 'a', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow([noise, H, num_params, train_mse, test_mse, train_err, test_err])

        all_results[noise] = results

    return all_results, threshold_params

def plot_results(all_results, threshold):
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), sharex=True)
    colors = ['blue', 'green', 'red']

    for i, noise in enumerate(NOISE_LEVELS):
        if noise not in all_results: continue
        res = all_results[noise]
        if not res['params']: continue

        label = f'Noise {int(noise*100)}%'
        ax1.plot(res['params'], res['train_mse'], 'o--', color=colors[i], label=label, markersize=4, alpha=0.7)
        ax2.plot(res['params'], res['test_mse'], 'o-', color=colors[i], label=label, markersize=4)

    for ax in [ax1, ax2]:
        ax.axvline(x=threshold, color='black', linestyle=':', label='Interpolation Threshold')
        ax.set_xscale('log')
        ax.set_yscale('log')
        ax.grid(True, which="both", ls="-", alpha=0.3)
        ax.legend()
        ax.set_ylabel('Mean Squared Error (MSE)')

    ax1.set_title(f'Train MSE (CIFAR-10, n={SUBSET_SIZE}, K={NUM_CLASSES})')
    ax2.set_title(f'Test MSE (CIFAR-10, n={SUBSET_SIZE}, K={NUM_CLASSES})')
    ax2.set_xlabel('Number of Parameters')

    output_file = 'cifar_double_descent_split_plot.png'
    plt.tight_layout()
    plt.savefig(output_file)
    print(f"\nPlot generated and saved to {output_file}")
    plt.show()

if __name__ == "__main__":
    data, threshold = run_experiment()
    if any(len(res['params']) > 0 for res in data.values()):
        plot_results(data, threshold)
    else:
        print("\nNo results generated.")